{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {
    "id": "e7f81904"
   },
   "source": [
    "# Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {
    "id": "2ff60aad"
   },
   "outputs": [],
   "source": [
    "!pip install transformers datasets evaluate accelerate scikit-learn pandas --quiet\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118 --quiet\n",
    "!pip install onnx onnxruntime-gpu optimum[onnxruntime-gpu] huggingface_hub --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {
    "id": "f994dd2f"
   },
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {
    "id": "d40ad631"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoConfig,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    EarlyStoppingCallback\n",
    ")\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from optimum.onnxruntime import ORTModelForSequenceClassification\n",
    "import onnxruntime as ort\n",
    "from huggingface_hub import Repository, create_repo, login\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {
    "id": "82f6652b"
   },
   "source": [
    "# Set Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {
    "id": "88c950d6"
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "    # Model Selection\n",
    "    MODEL_NAME = \"Shushant/nepaliBERT\"\n",
    "\n",
    "    # Training Hyperparameters\n",
    "    MAX_LENGTH = 256\n",
    "    BATCH_SIZE = 16\n",
    "    LEARNING_RATE = 2e-5\n",
    "    NUM_EPOCHS = 5\n",
    "    WARMUP_RATIO = 0.1\n",
    "    WEIGHT_DECAY = 0.01\n",
    "\n",
    "    # Class Configuration\n",
    "    NUM_LABELS = 3\n",
    "\n",
    "    # Data Split\n",
    "    TEST_SIZE = 0.15\n",
    "    VAL_SIZE = 0.15\n",
    "    RANDOM_SEED = 42\n",
    "\n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {
    "id": "c42e79c4"
   },
   "source": [
    "# Set cuda usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "83896630",
    "outputId": "b3a2e83a-7dfd-478a-b1b8-e02c7ea592f4"
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "if device == \"cuda\":\n",
    "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "    # Enable TF32 for faster training on Ampere GPUs\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True\n",
    "    torch.backends.cudnn.allow_tf32 = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {
    "id": "58e5f647"
   },
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {
    "id": "a35dc16a"
   },
   "outputs": [],
   "source": [
    "# Enter your kaggle username and key here\n",
    "# os.environ[\"KAGGLE_USERNAME\"] = \"\"\n",
    "# os.environ[\"KAGGLE_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4ac2bc5b",
    "outputId": "380009bc-da9c-4aa2-9bf9-1b776a24b145"
   },
   "outputs": [],
   "source": [
    "!kaggle datasets download -d mathew11111/nepcov19tweets -p . --unzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e89f69a8",
    "outputId": "ffffb1df-dc24-4e83-bf34-491a702663ff"
   },
   "outputs": [],
   "source": [
    "!curl -L -o dataset2.csv \"https://raw.githubusercontent.com/sagarl123/NepaliNLP-SentimentAnalysis/refs/heads/main/collected_labeled_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {
    "id": "d2b0710b"
   },
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"covid19_tweeter_dataset.csv\")\n",
    "df2 = pd.read_csv(\"dataset2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {
    "id": "872e42b1"
   },
   "source": [
    "# Clean the dataset for use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {
    "id": "de3dee39"
   },
   "outputs": [],
   "source": [
    "df1 = df1[['Label', 'Tweet']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {
    "id": "4a804d3e"
   },
   "outputs": [],
   "source": [
    "df1.drop(df1.index[~df1['Label'].isin([-1, 0, 1])], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {
    "id": "d9029b3a"
   },
   "outputs": [],
   "source": [
    "df1 = df1.rename(columns={\n",
    "    \"Label\": \"labels\",\n",
    "    \"Tweet\": \"text\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {
    "id": "7ff5383b"
   },
   "outputs": [],
   "source": [
    "df1['labels'] = df1['labels'].map({1: 2, 0: 1, -1: 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bc2ad31f",
    "outputId": "b4e45e77-3e4e-4a6c-b15c-ed2419735f7c"
   },
   "outputs": [],
   "source": [
    "df2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {
    "id": "1fd3839b"
   },
   "outputs": [],
   "source": [
    "df2 = df2.rename(columns={\n",
    "    'label': 'labels'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {
    "id": "6267a852"
   },
   "outputs": [],
   "source": [
    "# Merge the dataframes\n",
    "df = pd.concat([df1, df2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {
    "id": "1525413b"
   },
   "outputs": [],
   "source": [
    "# Ensure labels and texts are in correct format\n",
    "df['labels'] = df['labels'].astype(int)\n",
    "df['text'] = df['text'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 210
    },
    "id": "05b1e82e",
    "outputId": "c60b4004-9a83-4e52-ee03-06eafa996895"
   },
   "outputs": [],
   "source": [
    "df['labels'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {
    "id": "2fe36f11"
   },
   "source": [
    "# Train Test Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {
    "id": "42ec9424"
   },
   "outputs": [],
   "source": [
    "train_df, temp_df = train_test_split(\n",
    "    df,\n",
    "    test_size=(config.TEST_SIZE + config.VAL_SIZE),\n",
    "    stratify=df['labels'],\n",
    "    random_state=config.RANDOM_SEED\n",
    ")\n",
    "\n",
    "val_df, test_df = train_test_split(\n",
    "    temp_df,\n",
    "    test_size=config.TEST_SIZE / (config.TEST_SIZE + config.VAL_SIZE),\n",
    "    stratify=temp_df['labels'],\n",
    "    random_state=config.RANDOM_SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4f588f35",
    "outputId": "e474e5df-113b-4cbc-9caa-73fbb9d029c9"
   },
   "outputs": [],
   "source": [
    "print(f\"   Train: {len(train_df)} samples\")\n",
    "print(f\"   Validation: {len(val_df)} samples\")\n",
    "print(f\"   Test: {len(test_df)} samples\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {
    "id": "ce3bd026"
   },
   "source": [
    "# Conversion to HuggingFace dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {
    "id": "5544c511"
   },
   "outputs": [],
   "source": [
    "dataset = DatasetDict({\n",
    "    'train': Dataset.from_pandas(train_df.reset_index(drop=True)),\n",
    "    'validation': Dataset.from_pandas(val_df.reset_index(drop=True)),\n",
    "    'test': Dataset.from_pandas(test_df.reset_index(drop=True))\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {
    "id": "ceba38f2"
   },
   "source": [
    "# Load Tokenizer and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "be43f534",
    "outputId": "5ba4e1e2-76ba-401a-ac1f-a3493a52977a"
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(config.MODEL_NAME)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    config.MODEL_NAME,\n",
    "    num_labels=config.NUM_LABELS,\n",
    "    problem_type=\"single_label_classification\",\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {
    "id": "3a3c42d9"
   },
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {
    "id": "a3c393b6"
   },
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    \"\"\"Tokenize text with proper padding and truncation\"\"\"\n",
    "    return tokenizer(\n",
    "        examples[\"text\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=config.MAX_LENGTH,\n",
    "        return_tensors=None\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 113,
     "referenced_widgets": [
      "41fa4ee2c3d4482c8fcbb5b2ffd57fe2",
      "96db85bd6fc443ad848c97eb827c6a57",
      "dff438a3e2ac4722a09b5317f65e529d",
      "cca0a1025cb6417fab4aaefa6482bab3",
      "ec1e55e1fec44aaca22caebec746c03b",
      "3bfc1be20eec4b619b70c5a11f94115b",
      "29c5dab527d040bfbd5f673248c57d28",
      "803c27f76c584ee0be965a87742502ea",
      "b781ee1f746048ada156aea52e25cf75",
      "5b09d498b8ec48308f912f9415075617",
      "ef29b55cfd1942e284bb0d2632573049",
      "18f190415e064486b0e07fa812fa30cd",
      "ad351878879b489a808eedb514496b2b",
      "cdcccd8d148849b1bee318d00c97fce4",
      "d55ea638616f44de8022c95d65510111",
      "11d37647e97c499bb91f124a17973567",
      "72751a4c1210434b94f3fe640727725a",
      "0c0778fc6d704f27af67e5f6be606df5",
      "ab3d8be6fca14f068ffb0acf3c7530e2",
      "602153db7f4c40c695ddd1474c22e567",
      "045fa8983aab4ff5be25ca3f7f950019",
      "e577973cf7af4126914368799f9ebf54",
      "005345f2beaf439db054b50e25c57e07",
      "43a5f48c881f467d8deaac2ca90479c4",
      "b1cf398dbd9b4f328034aec335420f8b",
      "cfbb67337c5a4ba6b965fa5ede9e6f2e",
      "879aefea63734f6f84e6bba7a30d91a2",
      "ce3ff10478cd47549e4f904ce0d11c02",
      "4cff34986571471ba1d71a916f94c614",
      "54798440c25a48c4add4472ac5952f17",
      "76045ad1ac654d12be105d2bd260057d",
      "da8ebcab7c0a4b02b9a29b8e6aa244ef",
      "9a4f04edfc5845e290c158c67974ed7b"
     ]
    },
    "id": "b93d9b9f",
    "outputId": "fc3603a9-18e0-4a7e-8e0a-6e1958c2506a"
   },
   "outputs": [],
   "source": [
    "tokenized_dataset = dataset.map(\n",
    "    tokenize_function,\n",
    "    batched=True,\n",
    "    remove_columns=[\"text\"]\n",
    ")\n",
    "tokenized_dataset.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {
    "id": "6e57b108"
   },
   "source": [
    "# Compute metrics for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {
    "id": "2cb05476"
   },
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    \"\"\"Calculate accuracy and macro F1 score\"\"\"\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "\n",
    "    macro_f1 = f1_score(labels, predictions, average='macro')\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "\n",
    "    # Per-class F1 scores\n",
    "    f1_per_class = f1_score(labels, predictions, average=None)\n",
    "\n",
    "    return {\n",
    "        'macro_f1': macro_f1,\n",
    "        'accuracy': accuracy,\n",
    "        'f1_negative': f1_per_class[0],\n",
    "        'f1_positive': f1_per_class[1],\n",
    "        'f1_neutral': f1_per_class[2]\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {
    "id": "c2a08c72"
   },
   "source": [
    "# Custom trainer with balanced class weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {
    "id": "89e4ad49"
   },
   "outputs": [],
   "source": [
    "class_weights = compute_class_weight(\n",
    "    'balanced',\n",
    "    classes=np.unique(train_df['labels']),\n",
    "    y=train_df['labels']\n",
    ")\n",
    "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {
    "id": "55badcd6"
   },
   "outputs": [],
   "source": [
    "class WeightedTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "\n",
    "        # Apply class weights to loss\n",
    "        loss_fct = torch.nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
    "        loss = loss_fct(logits, labels)\n",
    "\n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {
    "id": "748cbace"
   },
   "source": [
    "# Training arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {
    "id": "e30749a5"
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "\n",
    "    # Training hyperparameters\n",
    "    num_train_epochs=config.NUM_EPOCHS,\n",
    "    per_device_train_batch_size=config.BATCH_SIZE,\n",
    "    per_device_eval_batch_size=config.BATCH_SIZE * 2,\n",
    "    learning_rate=config.LEARNING_RATE,\n",
    "    weight_decay=config.WEIGHT_DECAY,\n",
    "    warmup_ratio=config.WARMUP_RATIO,\n",
    "\n",
    "    # Evaluation strategy\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"macro_f1\",\n",
    "    greater_is_better=True,\n",
    "\n",
    "    # Optimization\n",
    "    fp16=torch.cuda.is_available(),  # Mixed precision training\n",
    "    gradient_accumulation_steps=2,\n",
    "    gradient_checkpointing=False,\n",
    "\n",
    "    # Misc\n",
    "    save_total_limit=2,  # Keep only 2 best checkpoints\n",
    "    seed=config.RANDOM_SEED,\n",
    "    report_to=\"none\",\n",
    "    disable_tqdm=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {
    "id": "af60e2e1"
   },
   "source": [
    "# Initialize Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {
    "id": "ea77181b"
   },
   "outputs": [],
   "source": [
    "trainer = WeightedTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"validation\"],\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42",
   "metadata": {
    "id": "e75a2f84"
   },
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 232
    },
    "id": "a5adbbce",
    "outputId": "b8067855-5d49-43a3-9627-f12165af3a35"
   },
   "outputs": [],
   "source": [
    "train_result = trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44",
   "metadata": {
    "id": "1651a8b8"
   },
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 159
    },
    "id": "b7655f65",
    "outputId": "0b79e3d0-fd11-4958-f219-583bb8f43d8d"
   },
   "outputs": [],
   "source": [
    "test_results = trainer.evaluate(tokenized_dataset[\"test\"])\n",
    "print(\"Test Set Results:\")\n",
    "print(f\"   Macro F1 Score: {test_results['eval_macro_f1']:.4f}\")\n",
    "print(f\"   Accuracy: {test_results['eval_accuracy']:.4f}\")\n",
    "print(f\"   F1 (Negative): {test_results['eval_f1_negative']:.4f}\")\n",
    "print(f\"   F1 (Neutral): {test_results['eval_f1_neutral']:.4f}\")\n",
    "print(f\"   F1 (Positive): {test_results['eval_f1_positive']:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191
    },
    "id": "abc94bad",
    "outputId": "e7597b9a-ad86-46e7-b755-c1e15a08c82e"
   },
   "outputs": [],
   "source": [
    "# Detailed classification report\n",
    "predictions = trainer.predict(tokenized_dataset[\"test\"])\n",
    "y_pred = np.argmax(predictions.predictions, axis=1)\n",
    "y_true = predictions.label_ids\n",
    "\n",
    "print(classification_report(\n",
    "    y_true,\n",
    "    y_pred,\n",
    "    target_names=['Negative', 'Positive', 'Neutral'],\n",
    "    digits=4\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47",
   "metadata": {
    "id": "9cce9a98"
   },
   "source": [
    "# ONNX configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "488d8547",
    "outputId": "20ebcfe9-3b65-40e4-9a87-9437fed9fc56"
   },
   "outputs": [],
   "source": [
    "model = trainer.model\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49",
   "metadata": {
    "id": "7ececd98"
   },
   "source": [
    "# Export to ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {
    "id": "07ee5334"
   },
   "outputs": [],
   "source": [
    "model.save_pretrained(\"tmp_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {
    "id": "d51282ad"
   },
   "outputs": [],
   "source": [
    "ort_model = ORTModelForSequenceClassification.from_pretrained(\n",
    "    'tmp_model',\n",
    "    export=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {
    "id": "NJ4V-SzyV1GI"
   },
   "outputs": [],
   "source": [
    "ort_model.save_pretrained(\"tmp_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53",
   "metadata": {
    "id": "4a863e3f"
   },
   "source": [
    "# Verify onnx model's working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "94bfc682",
    "outputId": "1dc79c31-3a8e-494e-e6b8-fdac7afa0082"
   },
   "outputs": [],
   "source": [
    "# Test inference\n",
    "test_text = \"सेवाको गुणस्तर धेरै कमजोर छ, म सन्तुष्ट छैन।\"\n",
    "inputs = tokenizer(test_text, return_tensors=\"np\", padding=True, return_token_type_ids=True)\n",
    "\n",
    "onnx_path = Path('tmp_model') / 'model.onnx'\n",
    "\n",
    "ort_sess = ort.InferenceSession(str(onnx_path), providers=[\"CUDAExecutionProvider\"])\n",
    "\n",
    "inputs = {\n",
    "    \"input_ids\":       inputs[\"input_ids\"].astype(np.int64),\n",
    "    \"attention_mask\":  inputs[\"attention_mask\"].astype(np.int64),\n",
    "    \"token_type_ids\":  inputs[\"token_type_ids\"].astype(np.int64),\n",
    "}\n",
    "\n",
    "logits = ort_sess.run(\n",
    "    ['logits'],\n",
    "    inputs\n",
    ")\n",
    "\n",
    "print(\"ONNX logits:\", logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55",
   "metadata": {
    "id": "32ba8c3b"
   },
   "source": [
    "# Create model card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {
    "id": "c6ed573f"
   },
   "outputs": [],
   "source": [
    "model_card = f\"\"\"---\n",
    "language: ne\n",
    "license: apache-2.0\n",
    "tags:\n",
    "- sentiment-analysis\n",
    "- nepali\n",
    "- onnx\n",
    "- bert\n",
    "- text-classification\n",
    "datasets:\n",
    "- custom-nepali-sentiment\n",
    "metrics:\n",
    "- f1\n",
    "- accuracy\n",
    "model-index:\n",
    "- name: mohit4519/nepali-sentiment\n",
    "  results:\n",
    "  - task:\n",
    "      type: text-classification\n",
    "      name: Sentiment Analysis\n",
    "    dataset:\n",
    "      name: Nepali Sentiment Dataset\n",
    "      type: custom\n",
    "    metrics:\n",
    "    - type: f1\n",
    "      value: 0.XX  # Replace with your actual score\n",
    "      name: Macro F1\n",
    "---\n",
    "\n",
    "# Nepali Sentiment Analysis (ONNX)\n",
    "\n",
    "This model is a fine-tuned BERT model for Nepali sentiment analysis, exported to ONNX format for optimized inference.\n",
    "\n",
    "## Model Details\n",
    "\n",
    "- **Base Model**: Shushant/nepaliBERT\n",
    "- **Task**: Sentiment Classification (3-class)\n",
    "- **Labels**:\n",
    "  - 0: Negative\n",
    "  - 1: Positive\n",
    "  - 2: Neutral\n",
    "- **Format**: ONNX (optimized for fast inference)\n",
    "\n",
    "## Usage\n",
    "\n",
    "### Installation\n",
    "\n",
    "```bash\n",
    "pip install transformers optimum[onnxruntime]\n",
    "```\n",
    "\n",
    "### Inference\n",
    "\n",
    "```python\n",
    "from transformers import AutoTokenizer\n",
    "from optimum.onnxruntime import ORTModelForSequenceClassification\n",
    "import torch\n",
    "\n",
    "# Load model and tokenizer\n",
    "model = ORTModelForSequenceClassification.from_pretrained(\"mohit4519/nepali-sentiment\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"{config.MODEL_NAME}\")\n",
    "\n",
    "# Predict sentiment\n",
    "text = \"यो धेरै राम्रो छ\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "prediction = torch.argmax(outputs.logits, dim=-1).item()\n",
    "\n",
    "sentiment_map = {{0: 'Negative', 1: 'Positive', 2: 'Neutral'}}\n",
    "print(f\"Sentiment: {{sentiment_map[prediction]}}\")\n",
    "```\n",
    "\n",
    "## Performance\n",
    "\n",
    "- **Macro F1 Score**: 0.78\n",
    "- **Accuracy**: 0.8\n",
    "\n",
    "## Training Data\n",
    "\n",
    "Trained on Nepali sentiment dataset containing social media text, reviews, and comments.\n",
    "\n",
    "## Limitations\n",
    "\n",
    "- Best performance on Nepali text\n",
    "- May have reduced accuracy on code-mixed or transliterated text\n",
    "- Performance varies across different domains\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {
    "id": "R310bMTFfxP7"
   },
   "outputs": [],
   "source": [
    "# Write your model_card variable to README.md\n",
    "with open(os.path.join(Path('tmp_model'), \"README.md\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(model_card)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58",
   "metadata": {
    "id": "9d6c0631"
   },
   "source": [
    "# Add to HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 214,
     "referenced_widgets": [
      "4b8829cfb67e42988179109ccd813e06",
      "a9a598056de14064899144959088a263",
      "5af584505092472d846dc2d17c5d510c",
      "14a89f9b0dfc49388a8af4113a1c895c",
      "a66eb3a6b18e45c49f455d8ac8670c42",
      "c8e8618759594b788c041bbffc3f2bab",
      "b2b997fd4b194222a8e24948073a730e",
      "3999f5000de64ff282c6296e4cb817aa",
      "7f65e570e1694f61b0dea41812abfa73",
      "a1d42742c7564805a0887d4bcbebb620",
      "0e8568b61cc644d0a878026143618cbd",
      "b6bdcb6d25574f199fed1fcf23506580",
      "4bd3429d997045e9ad4099415d375643",
      "ff070e348d2a4d139b140f2fc971f408",
      "b08a10316c064c45ac1358202be5a918",
      "416ae6fe2640442382e0b2ebb57d63b1",
      "8574787008ca4a0c84b69be1270975ab",
      "50d3eac356034eaabec56da8ce44099d",
      "ccebeaab40a04c2e9cc5d1fe7051ee06",
      "039a5bc4e2df44f39dfc5966011b09dc",
      "8ea2efa85dd24935bef83cfe99e13560",
      "df42066db8db4b4cbda9beeb927180b8",
      "de7febfb015a4c8db49988ec91b1dd6e",
      "b5f43f2a647d4aeeb5d39df5cdbf9737",
      "40522c679897451395b151123020c446",
      "bd30a82948c248998b665a58de996331",
      "78aebe675c32478e976e10b8f8ad4bed",
      "bb7e47f619b54cf7835d450000043b08",
      "ddbb0db43aaa42799b34a6a5f88ee457",
      "1123a481c3064c2297b65786e410150a",
      "084dae7a75404a758d5817702de1ec4f",
      "24ac863e4451449aa2f6b5c3d05ce14b",
      "9f82c86d706a4facad323481dec9d8bb",
      "460870407bae4f89a3508f44f108c1fb",
      "7ce4373ac11e4b97828442cb7b562329",
      "20827fbf66db40f78ca2bef98affd3d2",
      "66bab5794ee24da988121ece2414582e",
      "c4bb5a03172e4ba7bbeb351c4f8d0875",
      "a3ee39fa647547769a4474c816281c78",
      "b83b946559354347bf44c3c9154a1835",
      "42a4dfe638bd4b36ba336b2d4af4e5c9",
      "113f67811e31464e92688e9405d075ea",
      "83e55977f5f746e3bbf33d97b5b7115c",
      "eb76616c3d894ab79d6aa94ff1ebbbc0"
     ]
    },
    "id": "PqM4i4-PnGeD",
    "outputId": "633c82c5-f886-45db-ff78-344903644826"
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import HfApi\n",
    "api.upload_folder(\n",
    "    folder_path=\"tmp_model\",\n",
    "    repo_id=\"mohit4519/nepali-sentiment\",\n",
    "    repo_type=\"model\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7f81904",
   "metadata": {},
   "source": [
    "# Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ff60aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers datasets evaluate accelerate scikit-learn pandas --quiet\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118 --quiet\n",
    "!pip install onnx onnxruntime-gpu optimum[onnxruntime-gpu] huggingface_hub --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f994dd2f",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d40ad631",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoConfig,\n",
    "    TrainingArguments, \n",
    "    Trainer,\n",
    "    EarlyStoppingCallback\n",
    ")\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from optimum.onnxruntime import ORTModelForSequenceClassification\n",
    "import onnxruntime as ort\n",
    "from huggingface_hub import HfApi, create_repo, login\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f6652b",
   "metadata": {},
   "source": [
    "# Set Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88c950d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    # Model Selection\n",
    "    MODEL_NAME = \"Shushant/nepaliBERT\"\n",
    "    \n",
    "    # Training Hyperparameters\n",
    "    MAX_LENGTH = 256\n",
    "    BATCH_SIZE = 16\n",
    "    LEARNING_RATE = 2e-5\n",
    "    NUM_EPOCHS = 5\n",
    "    WARMUP_RATIO = 0.1\n",
    "    WEIGHT_DECAY = 0.01\n",
    "    \n",
    "    # Class Configuration\n",
    "    NUM_LABELS = 3\n",
    "    \n",
    "    # Data Split\n",
    "    TEST_SIZE = 0.15\n",
    "    VAL_SIZE = 0.15\n",
    "    RANDOM_SEED = 42\n",
    "\n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42e79c4",
   "metadata": {},
   "source": [
    "# Set cuda usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83896630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "   GPU: Tesla T4\n",
      "   Memory: 15.83 GB\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "if device == \"cuda\":\n",
    "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "    # Enable TF32 for faster training on Ampere GPUs\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True\n",
    "    torch.backends.cudnn.allow_tf32 = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e5f647",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a35dc16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your kaggle username and key here\n",
    "# os.environ[\"KAGGLE_USERNAME\"] = \"\"\n",
    "# os.environ[\"KAGGLE_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ac2bc5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/bin/kaggle\", line 10, in <module>\n",
      "    sys.exit(main())\n",
      "             ^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/kaggle/cli.py\", line 68, in main\n",
      "    out = args.func(**command_args)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/kaggle/api/kaggle_api_extended.py\", line 1741, in dataset_download_cli\n",
      "    with self.build_kaggle_client() as kaggle:\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/kaggle/api/kaggle_api_extended.py\", line 688, in build_kaggle_client\n",
      "    username=self.config_values['username'],\n",
      "             ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'username'\n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets download -d mathew11111/nepcov19tweets -p . --unzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e89f69a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 1822k  100 1822k    0     0  4226k      0 --:--:-- --:--:-- --:--:-- 4219k\n"
     ]
    }
   ],
   "source": [
    "!curl -L -o dataset2.csv \"https://raw.githubusercontent.com/sagarl123/NepaliNLP-SentimentAnalysis/refs/heads/main/collected_labeled_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2b0710b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"covid19_tweeter_dataset.csv\")\n",
    "df2 = pd.read_csv(\"dataset2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872e42b1",
   "metadata": {},
   "source": [
    "# Clean the dataset for use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de3dee39",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1[['Label', 'Tweet']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a804d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.drop(df1.index[~df1['Label'].isin([-1, 0, 1])], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9029b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.rename(columns={\n",
    "    \"Label\": \"labels\",\n",
    "    \"Tweet\": \"text\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ff5383b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['labels'] = df1['labels'].map({0: 2, -1: 0, 1: 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc2ad31f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['text', 'label'], dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1fd3839b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.rename(columns={\n",
    "    'label': 'labels'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6267a852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the dataframes\n",
    "df = pd.concat([df1, df2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1525413b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure labels and texts are in correct format\n",
    "df['labels'] = df['labels'].astype(int)\n",
    "df['text'] = df['text'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "05b1e82e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>labels</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div><br><label><b>dtype:</b> int64</label>"
      ],
      "text/plain": [
       "labels\n",
       "1    3662\n",
       "0    2398\n",
       "2    1931\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['labels'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe36f11",
   "metadata": {},
   "source": [
    "# Train Test Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "42ec9424",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, temp_df = train_test_split(\n",
    "    df, \n",
    "    test_size=(config.TEST_SIZE + config.VAL_SIZE),\n",
    "    stratify=df['labels'],\n",
    "    random_state=config.RANDOM_SEED\n",
    ")\n",
    "\n",
    "val_df, test_df = train_test_split(\n",
    "    temp_df,\n",
    "    test_size=config.TEST_SIZE / (config.TEST_SIZE + config.VAL_SIZE),\n",
    "    stratify=temp_df['labels'],\n",
    "    random_state=config.RANDOM_SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4f588f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Train: 5593 samples\n",
      "   Validation: 1199 samples\n",
      "   Test: 1199 samples\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"   Train: {len(train_df)} samples\")\n",
    "print(f\"   Validation: {len(val_df)} samples\")\n",
    "print(f\"   Test: {len(test_df)} samples\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3bd026",
   "metadata": {},
   "source": [
    "# Conversion to HuggingFace dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5544c511",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DatasetDict({\n",
    "    'train': Dataset.from_pandas(train_df.reset_index(drop=True)),\n",
    "    'validation': Dataset.from_pandas(val_df.reset_index(drop=True)),\n",
    "    'test': Dataset.from_pandas(test_df.reset_index(drop=True))\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceba38f2",
   "metadata": {},
   "source": [
    "# Load Tokenizer and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "22913d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(config.MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "be43f534",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at Shushant/nepaliBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(config.MODEL_NAME)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    config.MODEL_NAME, \n",
    "    num_labels=config.NUM_LABELS,\n",
    "    problem_type=\"single_label_classification\",\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3c42d9",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a3c393b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    \"\"\"Tokenize text with proper padding and truncation\"\"\"\n",
    "    return tokenizer(\n",
    "        examples[\"text\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=config.MAX_LENGTH,\n",
    "        return_tensors=None \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b93d9b9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "160c0e9e89d84b0abcbd0ab2aa5e0a19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5593 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fef77ea13ae64079872ea324234e3122",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1199 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb9ca49244484a2c84f793a803c8a4bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1199 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_dataset = dataset.map(\n",
    "    tokenize_function,\n",
    "    batched=True,\n",
    "    remove_columns=[\"text\"]\n",
    ")\n",
    "tokenized_dataset.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e57b108",
   "metadata": {},
   "source": [
    "# Compute metrics for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2cb05476",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    \"\"\"Calculate accuracy and macro F1 score\"\"\"\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    macro_f1 = f1_score(labels, predictions, average='macro')\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    \n",
    "    # Per-class F1 scores\n",
    "    f1_per_class = f1_score(labels, predictions, average=None)\n",
    "    \n",
    "    return {\n",
    "        'macro_f1': macro_f1,\n",
    "        'accuracy': accuracy,\n",
    "        'f1_negative': f1_per_class[0],\n",
    "        'f1_neutral': f1_per_class[1],\n",
    "        'f1_positive': f1_per_class[2]\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a08c72",
   "metadata": {},
   "source": [
    "# Custom trainer with balanced class weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "89e4ad49",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = compute_class_weight(\n",
    "    'balanced',\n",
    "    classes=np.unique(train_df['labels']),\n",
    "    y=train_df['labels']\n",
    ")\n",
    "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "55badcd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightedTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        \n",
    "        # Apply class weights to loss\n",
    "        loss_fct = torch.nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
    "        loss = loss_fct(logits, labels)\n",
    "        \n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748cbace",
   "metadata": {},
   "source": [
    "# Training arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e30749a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    \n",
    "    # Training hyperparameters\n",
    "    num_train_epochs=config.NUM_EPOCHS,\n",
    "    per_device_train_batch_size=config.BATCH_SIZE,\n",
    "    per_device_eval_batch_size=config.BATCH_SIZE * 2,\n",
    "    learning_rate=config.LEARNING_RATE,\n",
    "    weight_decay=config.WEIGHT_DECAY,\n",
    "    warmup_ratio=config.WARMUP_RATIO,\n",
    "    \n",
    "    # Evaluation strategy\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"macro_f1\",\n",
    "    greater_is_better=True,\n",
    "    \n",
    "    # Optimization\n",
    "    fp16=torch.cuda.is_available(),  # Mixed precision training\n",
    "    gradient_accumulation_steps=2,\n",
    "    gradient_checkpointing=False,\n",
    "    \n",
    "    # Misc\n",
    "    save_total_limit=2,  # Keep only 2 best checkpoints\n",
    "    seed=config.RANDOM_SEED,\n",
    "    report_to=\"none\",\n",
    "    disable_tqdm=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af60e2e1",
   "metadata": {},
   "source": [
    "# Initialize Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ea77181b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = WeightedTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"validation\"],\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75a2f84",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a5adbbce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='875' max='875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [875/875 06:22, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Macro F1</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Negative</th>\n",
       "      <th>F1 Neutral</th>\n",
       "      <th>F1 Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.619591</td>\n",
       "      <td>0.742633</td>\n",
       "      <td>0.759800</td>\n",
       "      <td>0.746601</td>\n",
       "      <td>0.836472</td>\n",
       "      <td>0.644828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.579024</td>\n",
       "      <td>0.762645</td>\n",
       "      <td>0.777314</td>\n",
       "      <td>0.740634</td>\n",
       "      <td>0.860735</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.624000</td>\n",
       "      <td>0.602668</td>\n",
       "      <td>0.767206</td>\n",
       "      <td>0.783153</td>\n",
       "      <td>0.766404</td>\n",
       "      <td>0.855212</td>\n",
       "      <td>0.680000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.624000</td>\n",
       "      <td>0.679727</td>\n",
       "      <td>0.764425</td>\n",
       "      <td>0.784821</td>\n",
       "      <td>0.765499</td>\n",
       "      <td>0.861111</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.624000</td>\n",
       "      <td>0.730130</td>\n",
       "      <td>0.769058</td>\n",
       "      <td>0.789825</td>\n",
       "      <td>0.769022</td>\n",
       "      <td>0.864469</td>\n",
       "      <td>0.673684</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_result = trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1651a8b8",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b7655f65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Results:\n",
      "   Macro F1 Score: 0.7391\n",
      "   Accuracy: 0.7631\n",
      "   F1 (Negative): 0.7454\n",
      "   F1 (Neutral): 0.8486\n",
      "   F1 (Positive): 0.6233\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_results = trainer.evaluate(tokenized_dataset[\"test\"])\n",
    "print(\"Test Set Results:\")\n",
    "print(f\"   Macro F1 Score: {test_results['eval_macro_f1']:.4f}\")\n",
    "print(f\"   Accuracy: {test_results['eval_accuracy']:.4f}\")\n",
    "print(f\"   F1 (Negative): {test_results['eval_f1_negative']:.4f}\")\n",
    "print(f\"   F1 (Neutral): {test_results['eval_f1_neutral']:.4f}\")\n",
    "print(f\"   F1 (Positive): {test_results['eval_f1_positive']:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "abc94bad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative     0.7550    0.7361    0.7454       360\n",
      "     Neutral     0.8463    0.8509    0.8486       550\n",
      "    Positive     0.6169    0.6298    0.6233       289\n",
      "\n",
      "    accuracy                         0.7631      1199\n",
      "   macro avg     0.7394    0.7389    0.7391      1199\n",
      "weighted avg     0.7636    0.7631    0.7633      1199\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Detailed classification report\n",
    "predictions = trainer.predict(tokenized_dataset[\"test\"])\n",
    "y_pred = np.argmax(predictions.predictions, axis=1)\n",
    "y_true = predictions.label_ids\n",
    "\n",
    "print(classification_report(\n",
    "    y_true, \n",
    "    y_pred, \n",
    "    target_names=['Negative', 'Neutral', 'Positive'],\n",
    "    digits=4\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cce9a98",
   "metadata": {},
   "source": [
    "# ONNX configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "488d8547",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = trainer.model\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e215a35f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1aadfd105e446799372ad5f424520a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Login to HF\n",
    "login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ececd98",
   "metadata": {},
   "source": [
    "# Export to ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "07ee5334",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"tmp_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d51282ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "ort_model = ORTModelForSequenceClassification.from_pretrained(\n",
    "    'tmp_model',\n",
    "    export=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a863e3f",
   "metadata": {},
   "source": [
    "# Verify onnx model's working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "94bfc682",
   "metadata": {},
   "outputs": [
    {
     "ename": "NoSuchFile",
     "evalue": "[ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from tmp_model/onnx/model.onnx failed:Load model tmp_model/onnx/model.onnx failed. File doesn't exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNoSuchFile\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-597096075.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0monnx_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tmp_model'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m'onnx'\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m'model.onnx'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mort_sess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mort\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInferenceSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0monnx_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproviders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"CUDAExecutionProvider\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m logits = ort_sess.run(\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/onnxruntime/capi/onnxruntime_inference_collection.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_bytes, sess_options, providers, provider_options, **kwargs)\u001b[0m\n\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 485\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_inference_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproviders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprovider_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisabled_optimizers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    486\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_enable_fallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/onnxruntime/capi/onnxruntime_inference_collection.py\u001b[0m in \u001b[0;36m_create_inference_session\u001b[0;34m(self, providers, provider_options, disabled_optimizers)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_path\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m             \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInferenceSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_config_from_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    574\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m             \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInferenceSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_bytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_config_from_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNoSuchFile\u001b[0m: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from tmp_model/onnx/model.onnx failed:Load model tmp_model/onnx/model.onnx failed. File doesn't exist"
     ]
    }
   ],
   "source": [
    "# Test inference\n",
    "test_text = \"यो धेरै राम्रो छ\"\n",
    "inputs = tokenizer(test_text, return_tensors=\"pt\")\n",
    "\n",
    "onnx_path = Path('tmp_model') / 'onnx' / 'model.onnx'\n",
    "\n",
    "ort_sess = ort.InferenceSession(str(onnx_path), providers=[\"CUDAExecutionProvider\"])\n",
    "\n",
    "logits = ort_sess.run(\n",
    "    None,\n",
    "    {\n",
    "        \"input_ids\": inputs[\"input_ids\"].cpu().numpy(),\n",
    "        \"attention_mask\": inputs[\"attention_mask\"].cpu().numpy()\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"ONNX logits:\", logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ba8c3b",
   "metadata": {},
   "source": [
    "# Create model card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ed573f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_card = f\"\"\"---\n",
    "language: ne\n",
    "license: apache-2.0\n",
    "tags:\n",
    "- sentiment-analysis\n",
    "- nepali\n",
    "- onnx\n",
    "- bert\n",
    "- text-classification\n",
    "datasets:\n",
    "- custom-nepali-sentiment\n",
    "metrics:\n",
    "- f1\n",
    "- accuracy\n",
    "model-index:\n",
    "- name: {HF_REPO_NAME}\n",
    "  results:\n",
    "  - task:\n",
    "      type: text-classification\n",
    "      name: Sentiment Analysis\n",
    "    dataset:\n",
    "      name: Nepali Sentiment Dataset\n",
    "      type: custom\n",
    "    metrics:\n",
    "    - type: f1\n",
    "      value: 0.XX  # Replace with your actual score\n",
    "      name: Macro F1\n",
    "---\n",
    "\n",
    "# Nepali Sentiment Analysis (ONNX)\n",
    "\n",
    "This model is a fine-tuned BERT model for Nepali sentiment analysis, exported to ONNX format for optimized inference.\n",
    "\n",
    "## Model Details\n",
    "\n",
    "- **Base Model**: Shushant/nepaliBERT (or your base model)\n",
    "- **Task**: Sentiment Classification (3-class)\n",
    "- **Labels**: \n",
    "  - 0: Negative\n",
    "  - 1: Neutral\n",
    "  - 2: Positive\n",
    "- **Format**: ONNX (optimized for fast inference)\n",
    "\n",
    "## Usage\n",
    "\n",
    "### Installation\n",
    "\n",
    "```bash\n",
    "pip install transformers optimum[onnxruntime]\n",
    "```\n",
    "\n",
    "### Inference\n",
    "\n",
    "```python\n",
    "from transformers import AutoTokenizer\n",
    "from optimum.onnxruntime import ORTModelForSequenceClassification\n",
    "import torch\n",
    "\n",
    "# Load model and tokenizer\n",
    "model = ORTModelForSequenceClassification.from_pretrained(\"{HF_REPO_ID}\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"{HF_REPO_ID}\")\n",
    "\n",
    "# Predict sentiment\n",
    "text = \"यो धेरै राम्रो छ\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "prediction = torch.argmax(outputs.logits, dim=-1).item()\n",
    "\n",
    "sentiment_map = {{-1: 'Negative', 0: 'Neutral', 1: 'Positive'}}\n",
    "print(f\"Sentiment: {{sentiment_map[prediction]}}\")\n",
    "```\n",
    "\n",
    "## Performance\n",
    "\n",
    "- **Macro F1 Score**: 0.XX (Replace with your score)\n",
    "- **Accuracy**: 0.XX (Replace with your score)\n",
    "\n",
    "## Training Data\n",
    "\n",
    "Trained on Nepali sentiment dataset containing social media text, reviews, and comments.\n",
    "\n",
    "## Limitations\n",
    "\n",
    "- Best performance on Nepali text\n",
    "- May have reduced accuracy on code-mixed or transliterated text\n",
    "- Performance varies across different domains\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6c0631",
   "metadata": {},
   "source": [
    "# Add to HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9c59fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_name = 'mohit4519/nepali-sentiment'\n",
    "repo = Repository(local_dir=\"onnx_hf_repo\", clone_from=repo_name)\n",
    "\n",
    "# Copy files to repo\n",
    "import shutil\n",
    "shutil.copytree(onnx_export_dir, \"onnx_hf_repo/onnx_model\", dirs_exist_ok=True)\n",
    "tokenizer.save_pretrained(\"onnx_hf_repo/tokenizer\")\n",
    "\n",
    "# Commit & push\n",
    "repo.push_to_hub(commit_message=\"Add fine-tuned GPU-optimized ONNX sentiment model\")\n",
    "\n",
    "print(f\"✅ Model uploaded to Hugging Face Hub: {repo_name}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
